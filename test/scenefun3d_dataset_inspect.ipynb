{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mask3d_cuda113/lib/python3.10/site-packages/MinkowskiEngine-0.5.4-py3.10-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# set current dir to Mask3D dir\n",
    "mask3d_dir = \"/workspace/Mask3D_adapted\"\n",
    "os.chdir(mask3d_dir)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from hashlib import md5\n",
    "from uuid import uuid4\n",
    "import hydra\n",
    "from dotenv import load_dotenv\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from trainer.trainer import InstanceSegmentation, RegularCheckpointing\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils.utils import (\n",
    "    flatten_dict,\n",
    "    load_baseline_model,\n",
    "    load_checkpoint_with_missing_or_exsessive_keys,\n",
    "    load_backbone_checkpoint_with_missing_or_exsessive_keys,\n",
    ")\n",
    "from datasets.utils import *\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from random import random, sample, uniform\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "from datasets.random_cuboid import RandomCuboid\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import scipy\n",
    "import volumentations as V\n",
    "import yaml\n",
    "\n",
    "# from yaml import CLoader as Loader\n",
    "from torch.utils.data import Dataset\n",
    "from datasets.scannet200.scannet200_constants import (\n",
    "    SCANNET_COLOR_MAP_200,\n",
    "    SCANNET_COLOR_MAP_20,\n",
    ")\n",
    "MULTISCAN_COLOR_MAP = {0: (0.0, 0.0, 0.0),\n",
    " 1: (191, 246, 112),\n",
    " 2: (110, 239, 148),\n",
    " 255: (0.0, 0.0, 0.0),}\n",
    "from datasets.scannetpp.scannetpp_constants import (SCANNETPP_COLOR_MAP)\n",
    "\n",
    "# models \n",
    "from models.mask3d import *\n",
    "\n",
    "def elastic_distortion(pointcloud, granularity, magnitude):\n",
    "    \"\"\"Apply elastic distortion on sparse coordinate space.\n",
    "\n",
    "    pointcloud: numpy array of (number of points, at least 3 spatial dims)\n",
    "    granularity: size of the noise grid (in same scale[m/cm] as the voxel grid)\n",
    "    magnitude: noise multiplier\n",
    "    \"\"\"\n",
    "    blurx = np.ones((3, 1, 1, 1)).astype(\"float32\") / 3\n",
    "    blury = np.ones((1, 3, 1, 1)).astype(\"float32\") / 3\n",
    "    blurz = np.ones((1, 1, 3, 1)).astype(\"float32\") / 3\n",
    "    coords = pointcloud[:, :3]\n",
    "    coords_min = coords.min(0)\n",
    "\n",
    "    # Create Gaussian noise tensor of the size given by granularity.\n",
    "    noise_dim = ((coords - coords_min).max(0) // granularity).astype(int) + 3\n",
    "    noise = np.random.randn(*noise_dim, 3).astype(np.float32)\n",
    "\n",
    "    # Smoothing.\n",
    "    for _ in range(2):\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurx, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blury, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurz, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Trilinear interpolate noise filters for each spatial dimensions.\n",
    "    ax = [\n",
    "        np.linspace(d_min, d_max, d)\n",
    "        for d_min, d_max, d in zip(\n",
    "            coords_min - granularity,\n",
    "            coords_min + granularity * (noise_dim - 2),\n",
    "            noise_dim,\n",
    "        )\n",
    "    ]\n",
    "    interp = scipy.interpolate.RegularGridInterpolator(\n",
    "        ax, noise, bounds_error=0, fill_value=0\n",
    "    )\n",
    "    pointcloud[:, :3] = coords + interp(coords) * magnitude\n",
    "    return pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import random\n",
    "from datasets.semseg import SemanticSegmentationArticulationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.use_coarse_to_fine:  False\n",
      "type(self.use_coarse_to_fine):  <class 'bool'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Mask3D_adapted/datasets/semseg.py:920: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  file = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "dataaset = SemanticSegmentationArticulationDataset(\n",
    "        dataset_name=\"scenefun3d\",\n",
    "        data_dir = \"data/processed/scenefun3d\",\n",
    "        label_db_filepath = \"data/processed/scenefun3d/label_database.yaml\",\n",
    "        color_mean_std = \"data/processed/scenefun3d/color_mean_std.yaml\",\n",
    "        mode = \"validation\",\n",
    "        add_colors = True,\n",
    "        add_normals = False,\n",
    "        add_raw_coordinates = True,\n",
    "        add_instance = True,\n",
    "        num_labels = 3,\n",
    "        data_percent = 1.0,\n",
    "        ignore_label = 255,\n",
    "        volume_augmentations_path = None,\n",
    "        image_augmentations_path = None,\n",
    "        instance_oversampling=0,\n",
    "        place_around_existing=False,\n",
    "        max_cut_region=0,\n",
    "        point_per_cut=0,\n",
    "        flip_in_center=False,\n",
    "        noise_rate=0.0,\n",
    "        resample_points=0.0,\n",
    "        cache_data=False,\n",
    "        add_unlabeled_pc=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        cropping=False,\n",
    "        cropping_args=None,\n",
    "        is_tta=False,\n",
    "        crop_min_size=20000,\n",
    "        crop_length=6.0,\n",
    "        cropping_v1=True,\n",
    "        reps_per_epoch=1,\n",
    "        area=-1,\n",
    "        on_crops=False,\n",
    "        eval_inner_core=-1,\n",
    "        filter_out_classes=[0, 255],\n",
    "        label_offset=0,\n",
    "        add_clip=False,\n",
    "        is_elastic_distortion=True,\n",
    "        color_drop=0.0,\n",
    "        load_articulation = True\n",
    ")\n",
    "collater = VoxelizeCollate(\n",
    "        ignore_label=255,\n",
    "        voxel_size=0.01,\n",
    "        mode=\"train_mode\",\n",
    "        small_crops=False,\n",
    "        very_small_crops=False,\n",
    "        batch_instance=False,\n",
    "        probing=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        ignore_class_threshold=100,\n",
    "        filter_out_classes=[0, 255],\n",
    "        label_offset=0,\n",
    "        num_queries=150,\n",
    "        load_articulation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataaset)):\n",
    "    if dataaset[i][3] == '421393':\n",
    "        print(i)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = collater([dataaset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2]),\n",
       " 'masks': tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True,  True,  True]]),\n",
       " 'segment_mask': tensor([[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]]),\n",
       " 'articulations': {'origin': tensor([[-9.4077e-01, -7.0117e-01,  1.4104e+02],\n",
       "          [ 9.3317e-01, -4.7149e-01,  1.4151e+02],\n",
       "          [ 9.3034e-01, -4.7626e-01,  1.4134e+02],\n",
       "          [ 9.2718e-01, -4.7698e-01,  1.4116e+02],\n",
       "          [ 9.3130e-01, -4.6246e-01,  1.4098e+02],\n",
       "          [ 5.0210e-01, -8.6607e-01,  1.4188e+02],\n",
       "          [ 1.1668e+00, -1.1262e+00,  1.4188e+02],\n",
       "          [-1.1223e+00, -6.7075e-01,  1.4223e+02],\n",
       "          [-1.0765e+00,  1.1801e-01,  1.4170e+02],\n",
       "          [ 2.0274e-02, -1.1586e+00,  1.4089e+02],\n",
       "          [-6.6014e-02, -1.1219e+00,  1.4089e+02]]),\n",
       "  'axis': tensor([[ 0.0000,  0.0000, -1.0000],\n",
       "          [-0.9217,  0.3880,  0.0048],\n",
       "          [-0.9246,  0.3810,  0.0022],\n",
       "          [-0.9246,  0.3810,  0.0022],\n",
       "          [-0.9268,  0.3754, -0.0051],\n",
       "          [ 0.0000,  0.0000,  1.0000],\n",
       "          [ 0.0000,  0.0000, -1.0000],\n",
       "          [-0.3931, -0.9194,  0.0111],\n",
       "          [ 0.0000,  0.0000, -1.0000],\n",
       "          [-0.4135, -0.9105, -0.0077],\n",
       "          [-0.4135, -0.9105, -0.0077]])},\n",
       " 'articulations_dict': {tensor(1002): {'origin': array([ -0.9407676 ,  -0.70116866, 141.04195   ], dtype=float32),\n",
       "   'axis': array([ 0.,  0., -1.], dtype=float32)},\n",
       "  tensor(2003): {'origin': array([  0.93316615,  -0.4714905 , 141.51431   ], dtype=float32),\n",
       "   'axis': array([-0.92165774,  0.3879738 ,  0.00483045], dtype=float32)},\n",
       "  tensor(2004): {'origin': array([  0.93033725,  -0.47625932, 141.33525   ], dtype=float32),\n",
       "   'axis': array([-0.92456293,  0.38102323,  0.00216071], dtype=float32)},\n",
       "  tensor(2005): {'origin': array([  0.9271758 ,  -0.47697562, 141.16019   ], dtype=float32),\n",
       "   'axis': array([-0.92456293,  0.38102323,  0.00216071], dtype=float32)},\n",
       "  tensor(2006): {'origin': array([  0.9312963 ,  -0.46246195, 140.98099   ], dtype=float32),\n",
       "   'axis': array([-0.9268302 ,  0.3754456 , -0.00514368], dtype=float32)},\n",
       "  tensor(1007): {'origin': array([  0.5020995,  -0.8660669, 141.88188  ], dtype=float32),\n",
       "   'axis': array([0., 0., 1.], dtype=float32)},\n",
       "  tensor(1008): {'origin': array([  1.1668093,  -1.1261547, 141.88231  ], dtype=float32),\n",
       "   'axis': array([ 0.,  0., -1.], dtype=float32)},\n",
       "  tensor(2009): {'origin': array([ -1.1223065,  -0.6707499, 142.23276  ], dtype=float32),\n",
       "   'axis': array([-0.39307326, -0.91944075,  0.01105292], dtype=float32)},\n",
       "  tensor(1010): {'origin': array([-1.0765036e+00,  1.1800862e-01,  1.4169649e+02], dtype=float32),\n",
       "   'axis': array([ 0.,  0., -1.], dtype=float32)},\n",
       "  tensor(2011): {'origin': array([ 2.0273527e-02, -1.1585714e+00,  1.4089255e+02], dtype=float32),\n",
       "   'axis': array([-0.41352287, -0.9104616 , -0.00765207], dtype=float32)},\n",
       "  tensor(2012): {'origin': array([-6.6013597e-02, -1.1218525e+00,  1.4089243e+02], dtype=float32),\n",
       "   'axis': array([-0.41352287, -0.9104616 , -0.00765207], dtype=float32)}},\n",
       " 'point2segment': tensor([0, 0, 0,  ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1005, 1007, 1027, 1030, 1031], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"/workspace/Mask3D_adapted/data/processed/multiscan/instance_gt/validation/scene_00002_01.txt\"\n",
    "test = np.loadtxt(test_file).astype(np.int32)\n",
    "np.unique(test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, 26, 29, 30], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_batch[0].original_labels[0][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, 26, 29, 30], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[1][2][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = data_batch[1][0]['masks']\n",
    "\n",
    "inst_gt = np.zeros(masks.shape[1])\n",
    "for i in range(masks.shape[0]):\n",
    "    inst_mask = masks[i].numpy()\n",
    "    inst_gt[inst_mask] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_batch[0].coordinates[:, 1:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185682, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185682,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test2.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"inst.npy\", inst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<datasets.utils.NoGpu at 0x7fc5f0b37d00>,\n",
       " [{'labels': tensor([1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'masks': tensor([[False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           ...,\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False]]),\n",
       "   'segment_mask': tensor([[True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True]]),\n",
       "   'articulations': {'origin': tensor([[ 6.3476,  3.2623, -0.4918],\n",
       "            [ 5.6624,  3.5681, -0.3817],\n",
       "            [ 4.0854,  0.6979,  0.6094],\n",
       "            [ 3.3646,  0.6908,  0.6051],\n",
       "            [ 5.8573,  0.9283,  0.8430],\n",
       "            [ 5.8834,  0.9341,  0.8518],\n",
       "            [ 5.8672,  0.0332,  0.8492],\n",
       "            [ 2.8948,  2.8889, -0.3025],\n",
       "            [ 2.9814,  2.2026, -0.2670],\n",
       "            [ 4.0934,  0.6959, -0.0809],\n",
       "            [ 3.3590,  0.6930, -0.0733],\n",
       "            [ 4.0982,  0.7031, -0.7687],\n",
       "            [ 3.3632,  0.6784, -0.9456],\n",
       "            [ 3.3062,  0.6783,  0.4921],\n",
       "            [ 2.3817,  0.6727,  0.5614],\n",
       "            [ 3.2574,  0.6872, -0.5219],\n",
       "            [ 2.3891,  0.7002, -0.5300],\n",
       "            [ 2.3086,  0.6702,  0.5959],\n",
       "            [ 1.4692,  0.6722,  0.8084],\n",
       "            [ 2.2944,  0.6722, -0.0885],\n",
       "            [ 1.4673,  0.6637, -0.0871],\n",
       "            [ 2.3258,  0.6691, -0.9802],\n",
       "            [ 1.4788,  0.6607, -0.9804],\n",
       "            [ 5.8502,  1.8184,  0.8268]]),\n",
       "    'axis': tensor([[-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 4.8266e-03,  0.0000e+00,  9.9999e-01],\n",
       "            [ 2.9345e-02,  0.0000e+00,  9.9957e-01],\n",
       "            [-3.3512e-02,  0.0000e+00, -9.9944e-01],\n",
       "            [ 2.9345e-02,  0.0000e+00,  9.9957e-01],\n",
       "            [-1.4919e-02,  9.9989e-01, -1.7473e-04],\n",
       "            [ 5.0083e-02, -9.9875e-01, -2.2177e-16],\n",
       "            [ 9.0612e-04,  0.0000e+00, -1.0000e+00],\n",
       "            [ 1.0228e-02, -5.8350e-03,  9.9993e-01],\n",
       "            [-1.6870e-02,  0.0000e+00, -9.9986e-01],\n",
       "            [-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [ 0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [ 1.3275e-02,  2.5916e-03, -9.9991e-01],\n",
       "            [ 4.8266e-03,  0.0000e+00,  9.9999e-01],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01]])},\n",
       "   'point2segment': tensor([0, 0, 0,  ..., 0, 0, 0])}],\n",
       " ['scene_00004_00'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
