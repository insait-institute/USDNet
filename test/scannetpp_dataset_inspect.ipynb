{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mask3d_cuda113/lib/python3.10/site-packages/MinkowskiEngine-0.5.4-py3.10-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# set current dir to Mask3D dir\n",
    "mask3d_dir = \"/workspace/Mask3D_adapted\"\n",
    "os.chdir(mask3d_dir)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from hashlib import md5\n",
    "from uuid import uuid4\n",
    "import hydra\n",
    "from dotenv import load_dotenv\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from trainer.trainer import InstanceSegmentation, RegularCheckpointing\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils.utils import (\n",
    "    flatten_dict,\n",
    "    load_baseline_model,\n",
    "    load_checkpoint_with_missing_or_exsessive_keys,\n",
    "    load_backbone_checkpoint_with_missing_or_exsessive_keys,\n",
    ")\n",
    "from datasets.utils import *\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from random import random, sample, uniform\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "from datasets.random_cuboid import RandomCuboid\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import scipy\n",
    "import volumentations as V\n",
    "import yaml\n",
    "\n",
    "# from yaml import CLoader as Loader\n",
    "from torch.utils.data import Dataset\n",
    "from datasets.scannet200.scannet200_constants import (\n",
    "    SCANNET_COLOR_MAP_200,\n",
    "    SCANNET_COLOR_MAP_20,\n",
    ")\n",
    "from datasets.scannetpp.scannetpp_constants import (SCANNETPP_COLOR_MAP)\n",
    "\n",
    "# models \n",
    "from models.mask3d import *\n",
    "\n",
    "def elastic_distortion(pointcloud, granularity, magnitude):\n",
    "    \"\"\"Apply elastic distortion on sparse coordinate space.\n",
    "\n",
    "    pointcloud: numpy array of (number of points, at least 3 spatial dims)\n",
    "    granularity: size of the noise grid (in same scale[m/cm] as the voxel grid)\n",
    "    magnitude: noise multiplier\n",
    "    \"\"\"\n",
    "    blurx = np.ones((3, 1, 1, 1)).astype(\"float32\") / 3\n",
    "    blury = np.ones((1, 3, 1, 1)).astype(\"float32\") / 3\n",
    "    blurz = np.ones((1, 1, 3, 1)).astype(\"float32\") / 3\n",
    "    coords = pointcloud[:, :3]\n",
    "    coords_min = coords.min(0)\n",
    "\n",
    "    # Create Gaussian noise tensor of the size given by granularity.\n",
    "    noise_dim = ((coords - coords_min).max(0) // granularity).astype(int) + 3\n",
    "    noise = np.random.randn(*noise_dim, 3).astype(np.float32)\n",
    "\n",
    "    # Smoothing.\n",
    "    for _ in range(2):\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurx, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blury, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurz, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Trilinear interpolate noise filters for each spatial dimensions.\n",
    "    ax = [\n",
    "        np.linspace(d_min, d_max, d)\n",
    "        for d_min, d_max, d in zip(\n",
    "            coords_min - granularity,\n",
    "            coords_min + granularity * (noise_dim - 2),\n",
    "            noise_dim,\n",
    "        )\n",
    "    ]\n",
    "    interp = scipy.interpolate.RegularGridInterpolator(\n",
    "        ax, noise, bounds_error=0, fill_value=0\n",
    "    )\n",
    "    pointcloud[:, :3] = coords + interp(coords) * magnitude\n",
    "    return pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import random\n",
    "from datasets.semseg import SemanticSegmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Mask3D_adapted/datasets/semseg.py:711: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  file = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "dataaset = SemanticSegmentationDataset(\n",
    "        dataset_name=\"scannetpp\",\n",
    "        data_dir = \"data/processed/scannetpp\",\n",
    "        label_db_filepath = \"data/processed/scannetpp/label_database.yaml\",\n",
    "        color_mean_std = \"data/processed/scannetpp/color_mean_std.yaml\",\n",
    "        mode = \"train_validation\",\n",
    "        add_colors = True,\n",
    "        add_normals = False,\n",
    "        add_raw_coordinates = True,\n",
    "        add_instance = True,\n",
    "        num_labels = 100,\n",
    "        data_percent = 1.0,\n",
    "        ignore_label = 255,\n",
    "        volume_augmentations_path = None,\n",
    "        image_augmentations_path = None,\n",
    "        instance_oversampling=0,\n",
    "        place_around_existing=False,\n",
    "        max_cut_region=0,\n",
    "        point_per_cut=0,\n",
    "        flip_in_center=False,\n",
    "        noise_rate=0.0,\n",
    "        resample_points=0.0,\n",
    "        cache_data=False,\n",
    "        add_unlabeled_pc=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        cropping=False,\n",
    "        cropping_args=None,\n",
    "        is_tta=False,\n",
    "        crop_min_size=20000,\n",
    "        crop_length=6.0,\n",
    "        cropping_v1=True,\n",
    "        reps_per_epoch=1,\n",
    "        area=-1,\n",
    "        on_crops=False,\n",
    "        eval_inner_core=-1,\n",
    "        filter_out_classes=[0, 1 , 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 255],\n",
    "        label_offset=16,\n",
    "        add_clip=False,\n",
    "        is_elastic_distortion=True,\n",
    "        color_drop=0.0,\n",
    ")\n",
    "collater = VoxelizeCollate(\n",
    "        ignore_label=255,\n",
    "        voxel_size=0.02,\n",
    "        mode=\"train_mode\",\n",
    "        small_crops=False,\n",
    "        very_small_crops=False,\n",
    "        batch_instance=False,\n",
    "        probing=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        ignore_class_threshold=100,\n",
    "        filter_out_classes=[0, 1 , 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 255],\n",
    "        label_offset=16,\n",
    "        num_queries=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataaset._load_yaml(\"/workspace/Mask3D_adapted/data/processed/scannetpp/label_database.yaml\")\n",
    "_labels = dataaset._select_correct_labels(labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 100\n",
    "number_of_validation_labels = 0\n",
    "number_of_all_labels = 0\n",
    "for (\n",
    "    k,\n",
    "    v,\n",
    ") in labels.items():\n",
    "    number_of_all_labels += 1\n",
    "    if v[\"validation\"]:\n",
    "        number_of_validation_labels += 1\n",
    "\n",
    "if num_labels == number_of_all_labels:\n",
    "    pass\n",
    "elif num_labels == number_of_validation_labels:\n",
    "    valid_labels = dict()\n",
    "    for (\n",
    "        k,\n",
    "        v,\n",
    "    ) in labels.items():\n",
    "        if v[\"validation\"]:\n",
    "            valid_labels.update({k: v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scenes = [\"0d2ee665be\", \"3f15a9266d\", \"7b6477cb95\", \"3e8bba0176\", \"5f99900f09\", \"3db0a1c8f3\", \"5ee7c22ba0\", \"1ada7a0617\", \"5eb31827b7\", \"7bc286c1b6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataaset)):\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:  7bc286c1b6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.9327223e-06, -1.7310082e-07,  1.4993851e-05, ...,\n",
       "        2.8688519e+00,  2.8688748e+00,  2.8690846e+00], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[9][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:  7bc286c1b6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7, 17, 19, 43, 47, 53, 59, 60, 83, 95], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[9][2][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:  7bc286c1b6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 14, 15, 16, 44, 45, 46, 49, 64, 65], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[9][2][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:  7bc286c1b6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[9][2][:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:  0a5c013435\n",
      "Scene:  0a7cc12c0e\n",
      "Scene:  0a76e06478\n",
      "Scene:  0a184cf634\n",
      "Scene:  0b031f3119\n",
      "Scene:  0cf2e9402d\n",
      "Scene:  0e75f3c4d9\n",
      "Scene:  1a8e0d78c0\n",
      "Scene:  1a130d092a\n",
      "Scene:  1ae9e5d2a6\n",
      "Scene:  1b9692f0c7\n",
      "Scene:  1b75758486\n",
      "Scene:  1c4b893630\n",
      "Scene:  1d003b07bd\n",
      "Scene:  1f7cbbdde1\n",
      "Scene:  2a496183e1\n",
      "Scene:  2b1dc6d6a5\n",
      "Scene:  2e74812d00\n",
      "Scene:  3c95c89d61\n",
      "Scene:  3e928dc2f6\n",
      "Scene:  3f1e1610de\n",
      "Scene:  4a1a3a7dc5\n",
      "Scene:  4ba22fa7e4\n",
      "Scene:  4c5c60fa76\n",
      "Scene:  4ea827f5a1\n",
      "Scene:  5a269ba6fe\n",
      "Scene:  5d152fab1b\n",
      "Scene:  5fb5d2dbf2\n",
      "Scene:  6b40d1a939\n",
      "Scene:  6cc2231b9c\n",
      "Scene:  6d89a7320d\n",
      "Scene:  6ee2fc1070\n",
      "Scene:  6f1848d1e3\n",
      "Scene:  7cd2ac43b4\n",
      "Scene:  7e7cd69a59\n",
      "Scene:  7e09430da7\n",
      "Scene:  7eac902fd5\n",
      "Scene:  7f4d173c9c\n",
      "Scene:  07f5b601ee\n",
      "Scene:  07ff1c45bb\n",
      "Scene:  8a20d62ac0\n",
      "Scene:  8a35ef3cfe\n",
      "Scene:  8b2c0938d6\n",
      "Scene:  8b5caf3398\n",
      "Scene:  08bbbdcc3d\n",
      "Scene:  8be0cd3817\n",
      "Scene:  8d563fc2cc\n",
      "Scene:  8e00ac7f59\n",
      "Scene:  8e6ff28354\n",
      "Scene:  8f82c394d6\n",
      "Scene:  9b74afd2d2\n",
      "Scene:  09bced689e\n",
      "Scene:  9f21bdec45\n",
      "Scene:  9f139a318d\n",
      "Scene:  9f79564dbf\n",
      "Scene:  16c9bd2e1e\n",
      "Scene:  28a9ee4557\n",
      "Scene:  30f4a2b44d\n",
      "Scene:  036bce3393\n",
      "Scene:  37ea1c52f0\n",
      "Scene:  39e6ee46df\n",
      "Scene:  39f36da05b\n",
      "Scene:  40b56bf310\n",
      "Scene:  41b00feddb\n",
      "Scene:  45d2e33be1\n",
      "Scene:  47b37eb6f9\n",
      "Scene:  49a82360aa\n",
      "Scene:  54b6127146\n",
      "Scene:  55b2bf8036\n",
      "Scene:  56a0ec536c\n",
      "Scene:  59e3f1ea37\n",
      "Scene:  61adeff7d5\n",
      "Scene:  66c98f4a9b\n",
      "Scene:  67d702f2e8\n",
      "Scene:  69e5939669\n",
      "Scene:  75d29d69b8\n",
      "Scene:  076c822ecc\n",
      "Scene:  079a326597\n",
      "Scene:  80ffca8a48\n",
      "Scene:  87f6d7d564\n",
      "Scene:  88cf747085\n",
      "Scene:  94ee15e8ba\n",
      "Scene:  95d525fbfd\n",
      "Scene:  98b4ec142f\n",
      "Scene:  98fe276aa8\n",
      "Scene:  104acbf7d2\n",
      "Scene:  108ec0b806\n",
      "Scene:  210f741378\n",
      "Scene:  260db9cf5a\n",
      "Scene:  260fa55d50\n",
      "Scene:  280b83fcf3\n",
      "Scene:  281ba69af1\n",
      "Scene:  281bc17764\n",
      "Scene:  290ef3f2c9\n",
      "Scene:  302a7f6b67\n",
      "Scene:  320c3af000\n",
      "Scene:  324d07a5b3\n",
      "Scene:  355e5e32db\n",
      "Scene:  394a542a19\n",
      "Scene:  410c470782\n",
      "Scene:  419cbe7c11\n",
      "Scene:  480ddaadc0\n",
      "Scene:  484ad681df\n",
      "Scene:  646af5e14b\n",
      "Scene:  689fec23d7\n",
      "Scene:  709ab5bffe\n",
      "Scene:  712dc47104\n",
      "Scene:  785e7504b9\n",
      "Scene:  824d9cfa6e\n",
      "Scene:  893fb90e89\n",
      "Scene:  1204e08f17\n",
      "Scene:  1366d5ae89\n",
      "Scene:  1831b3823a\n",
      "Scene:  1841a0b525\n",
      "Scene:  2970e95b65\n",
      "Scene:  4318f8bb3c\n",
      "Scene:  6855e1ac32\n",
      "Scene:  7079b59642\n",
      "Scene:  8890d0a267\n",
      "Scene:  9460c8889d\n",
      "Scene:  9471b8d485\n",
      "Scene:  9859de300f\n",
      "Scene:  25927bb04c\n",
      "Scene:  30966f4c6e\n",
      "Scene:  32280ecbca\n",
      "Scene:  50809ea0d8\n",
      "Scene:  52599ae063\n",
      "Scene:  85251de7d1\n",
      "Scene:  88627b561e\n",
      "Scene:  89214f3ca0\n",
      "Scene:  303745abc7\n",
      "Scene:  961911d451\n",
      "Scene:  3928249b53\n",
      "Scene:  4422722c49\n",
      "Scene:  5654092cc2\n",
      "Scene:  8133208cb6\n",
      "Scene:  13285009a4\n",
      "Scene:  116456116b\n",
      "Scene:  251443268c\n",
      "Scene:  5656608266\n",
      "Scene:  6464461276\n",
      "Scene:  7977624358\n",
      "Scene:  a1d9da703c\n",
      "Scene:  a003a6585e\n",
      "Scene:  a4e227f506\n",
      "Scene:  a05ee63164\n",
      "Scene:  a08d9a2476\n",
      "Scene:  a08dda47a8\n",
      "Scene:  a29cccc784\n",
      "Scene:  a5114ca13d\n",
      "Scene:  aaa11940d3\n",
      "Scene:  ab046f8faf\n",
      "Scene:  ab6983ae6c\n",
      "Scene:  ab11145646\n",
      "Scene:  acd69a1746\n",
      "Scene:  ad2d07fd11\n",
      "Scene:  ada5304e41\n",
      "Scene:  b1d75ecd55\n",
      "Scene:  b08a908f0f\n",
      "Scene:  b20a261fdf\n",
      "Scene:  b26e64c4b0\n",
      "Scene:  b73f5cdc41\n",
      "Scene:  b5918e4637\n",
      "Scene:  b09431c547\n",
      "Scene:  b97261909e\n",
      "Scene:  bb87c292ad\n",
      "Scene:  bc2fce1d81\n",
      "Scene:  bc03d88fc3\n",
      "Scene:  bc400d86e1\n",
      "Scene:  bd7375297e\n",
      "Scene:  bd9305480d\n",
      "Scene:  be0ed6b33c\n",
      "Scene:  bf6e439e38\n",
      "Scene:  bfd3fd54d2\n",
      "Scene:  c0c863b72d\n",
      "Scene:  c0f5742640\n",
      "Scene:  c5f701a8c7\n",
      "Scene:  c06a983e63\n",
      "Scene:  c8f2218ee2\n",
      "Scene:  c9abde4c4b\n",
      "Scene:  c24f94007b\n",
      "Scene:  c173f62b15\n",
      "Scene:  c413b34238\n",
      "Scene:  c856c41c99\n",
      "Scene:  c47168fab2\n",
      "Scene:  c545851c4f\n",
      "Scene:  cbd4b3055e\n",
      "Scene:  ccfd3ed9c7\n",
      "Scene:  cf1ffd871d\n",
      "Scene:  d2f44bf242\n",
      "Scene:  d6cbe4b28b\n",
      "Scene:  d6d9ddb03f\n",
      "Scene:  d7abfc4b17\n",
      "Scene:  d415cc449b\n",
      "Scene:  d918af9c5f\n",
      "Scene:  d6702c681d\n",
      "Scene:  daffc70503\n",
      "Scene:  dc263dfbf0\n",
      "Scene:  dfac5b38df\n",
      "Scene:  e0abd740ba\n",
      "Scene:  e0de253456\n",
      "Scene:  e1b1d9de55\n",
      "Scene:  e01b287af5\n",
      "Scene:  e3ecd49e2b\n",
      "Scene:  e7ac609391\n",
      "Scene:  e8e81396b6\n",
      "Scene:  e8ea9b4da8\n",
      "Scene:  e9ac2fc517\n",
      "Scene:  e9e16b6043\n",
      "Scene:  e050c15a8d\n",
      "Scene:  e898c76c1f\n",
      "Scene:  e91722b5a3\n",
      "Scene:  eb4bc76767\n",
      "Scene:  ebc200e928\n",
      "Scene:  ed2216380b\n",
      "Scene:  ef18cf0708\n",
      "Scene:  ef69d58016\n",
      "Scene:  ef25276c25\n",
      "Scene:  f8f12e4e6b\n",
      "Scene:  f25f5e6f63\n",
      "Scene:  f34d532901\n",
      "Scene:  f248c2bcdc\n",
      "Scene:  f6659a3107\n",
      "Scene:  f07340dfea\n",
      "Scene:  f8062cb7ce\n",
      "Scene:  f5401524e5\n",
      "Scene:  faec2f0468\n",
      "Scene:  fb05e13ad1\n",
      "Scene:  fd361ab85f\n",
      "Scene:  fe1733741f\n",
      "Scene:  0d2ee665be\n",
      "Scene:  1ada7a0617\n",
      "Scene:  3db0a1c8f3\n",
      "Scene:  3e8bba0176\n",
      "Scene:  3f15a9266d\n",
      "Scene:  5eb31827b7\n",
      "Scene:  5ee7c22ba0\n",
      "Scene:  5f99900f09\n",
      "Scene:  7b6477cb95\n",
      "Scene:  7bc286c1b6\n",
      "Scene:  09c1414f1b\n",
      "Scene:  13c3e046d7\n",
      "Scene:  21d970d8de\n",
      "Scene:  25f3b7a318\n",
      "Scene:  27dd4da69e\n",
      "Scene:  31a2c91c43\n",
      "Scene:  38d58a7a31\n",
      "Scene:  40aec5fffa\n",
      "Scene:  45b0dac5e3\n",
      "Scene:  99fa5c25e1\n",
      "Scene:  286b55a2bf\n",
      "Scene:  825d228aec\n",
      "Scene:  5748ce6f01\n",
      "Scene:  6115eddb86\n",
      "Scene:  9071e139d9\n",
      "Scene:  578511c8a9\n",
      "Scene:  7831862f02\n",
      "Scene:  3864514494\n",
      "Scene:  5942004064\n",
      "Scene:  a8bf42d646\n",
      "Scene:  a24f64f7fb\n",
      "Scene:  a980334473\n",
      "Scene:  ac48a9b736\n",
      "Scene:  acd95847c5\n",
      "Scene:  b0a08200c9\n",
      "Scene:  bcd2436daf\n",
      "Scene:  bde1e479ad\n",
      "Scene:  c4c04e6d6c\n",
      "Scene:  c49a8c6cff\n",
      "Scene:  c50d2d1d42\n",
      "Scene:  c5439f4607\n",
      "Scene:  cc5237fd77\n",
      "Scene:  d755b3d9d8\n",
      "Scene:  e7af285f7d\n",
      "Scene:  e398684d27\n",
      "Scene:  f2dc06b1d2\n",
      "Scene:  f3d64c30f8\n",
      "Scene:  f9f95681fd\n",
      "Scene:  f3685d06a9\n",
      "Scene:  fb5a96b1a2\n"
     ]
    }
   ],
   "source": [
    "for i in range(280):\n",
    "    data_collate = collater([dataaset[i]])\n",
    "    labels = data_collate[1][0]['labels']\n",
    "    invalid_labels = labels[labels>=100]\n",
    "    if invalid_labels.shape[0]>0:\n",
    "        print(invalid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<datasets.utils.NoGpu at 0x7f639414db40>,\n",
       " [{'labels': tensor([67,  3, 37, 79, 27,  1, 31, 31, 44, 43]),\n",
       "   'masks': tensor([[False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           ...,\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ...,  True,  True,  True]]),\n",
       "   'segment_mask': tensor([[True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True]]),\n",
       "   'point2segment': tensor([0, 0, 0,  ..., 0, 0, 0])}],\n",
       " ['data'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "nodel_cfg_file = \"/workspace/Mask3D_adapted/test/model_conf.yaml\"\n",
    "def load_hydra_config(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = OmegaConf.load(f)\n",
    "    return config\n",
    "config = load_hydra_config(nodel_cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3d_model = Mask3D(\n",
    "    **config\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(x):\n",
    "    r\"\"\"Move all tensors to cuda.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = [to_cuda(item) for item in x]\n",
    "    elif isinstance(x, tuple):\n",
    "        x = (to_cuda(item) for item in x)\n",
    "    elif isinstance(x, dict):\n",
    "        x = {key: to_cuda(value) for key, value in x.items()}\n",
    "    elif isinstance(x, torch.Tensor):\n",
    "        x = x.cuda()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch_cuda = to_cuda(data_batch)\n",
    "data, target, file_names = data_batch_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_coordinates = data.features[:, -3:]\n",
    "data.features = data.features[:, :-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([244314, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ME.SparseTensor(\n",
    "    coordinates=data.coordinates,\n",
    "    features=data.features,\n",
    "    device=torch.device('cuda'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mask3d_model.forward(              \n",
    "    data,\n",
    "    point2segment=[\n",
    "        target[i][\"point2segment\"] for i in range(len(target))\n",
    "    ],\n",
    "    raw_coordinates=raw_coordinates,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_offset = dataaset.label_offset\n",
    "prediction = output[\"aux_outputs\"]\n",
    "prediction.append(\n",
    "    {\n",
    "        \"pred_logits\": output[\"pred_logits\"],\n",
    "        \"pred_masks\": output[\"pred_masks\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[-1][\n",
    "    \"pred_logits\"\n",
    "] = torch.functional.F.softmax(\n",
    "    prediction[-1][\"pred_logits\"], dim=-1\n",
    ")[\n",
    "    ..., :-1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_classes = list()\n",
    "all_pred_masks = list()\n",
    "all_pred_scores = list()\n",
    "all_heatmaps = list()\n",
    "all_query_pos = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_and_scores(\n",
    "    mask_cls, mask_pred, num_queries=100, num_classes=18, device=None\n",
    "):\n",
    "    labels = (\n",
    "        torch.arange(num_classes, device=device)\n",
    "        .unsqueeze(0)\n",
    "        .repeat(num_queries, 1)\n",
    "        .flatten(0, 1)\n",
    "    )\n",
    "\n",
    "    scores_per_query, topk_indices = mask_cls.flatten(0, 1).topk(\n",
    "        100, sorted=True\n",
    "    )\n",
    "    labels_per_query = labels[topk_indices]\n",
    "    topk_indices = topk_indices // num_classes\n",
    "    mask_pred = mask_pred[:, topk_indices]\n",
    "\n",
    "    result_pred_mask = (mask_pred > 0).float()\n",
    "    heatmap = mask_pred.float().sigmoid()\n",
    "\n",
    "    mask_scores_per_image = (heatmap * result_pred_mask).sum(0) / (\n",
    "        result_pred_mask.sum(0) + 1e-6\n",
    "    )\n",
    "    score = scores_per_query * mask_scores_per_image\n",
    "    classes = labels_per_query\n",
    "\n",
    "    return score, result_pred_mask, classes, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3d_model.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/2742014025.py:15: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_indices = topk_indices // num_classes\n"
     ]
    }
   ],
   "source": [
    "offset_coords_idx = 0\n",
    "classes_list = []\n",
    "for bid in range(len(prediction[-1][\"pred_masks\"])):\n",
    "    masks = (\n",
    "        prediction[-1][\"pred_masks\"][bid]\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "\n",
    "\n",
    "    scores, masks, classes, heatmap = get_mask_and_scores(\n",
    "        prediction[-1][\"pred_logits\"][bid]\n",
    "        .detach()\n",
    "        .cpu(),\n",
    "        masks,\n",
    "        prediction[-1][\"pred_logits\"][bid].shape[\n",
    "            0\n",
    "        ],\n",
    "        mask3d_model.num_classes - 1,\n",
    "    )\n",
    "\n",
    "    classes_list.append(classes)\n",
    "\n",
    "    # masks = self.get_full_res_mask(\n",
    "    #     masks,\n",
    "    #     inverse_maps[bid],\n",
    "    #     target_full_res[bid][\"point2segment\"],\n",
    "    # )\n",
    "\n",
    "    # heatmap = self.get_full_res_mask(\n",
    "    #     heatmap,\n",
    "    #     inverse_maps[bid],\n",
    "    #     target_full_res[bid][\"point2segment\"],\n",
    "    #     is_heatmap=True,\n",
    "    # )\n",
    "\n",
    "    # if backbone_features is not None:\n",
    "    #     backbone_features = self.get_full_res_mask(\n",
    "    #         torch.from_numpy(backbone_features),\n",
    "    #         inverse_maps[bid],\n",
    "    #         target_full_res[bid][\"point2segment\"],\n",
    "    #         is_heatmap=True,\n",
    "    #     )\n",
    "    #     backbone_features = backbone_features.numpy()\n",
    "\n",
    "    # masks = masks.numpy()\n",
    "    # heatmap = heatmap.numpy()\n",
    "\n",
    "    # sort_scores = scores.sort(descending=True)\n",
    "    # sort_scores_index = sort_scores.indices.cpu().numpy()\n",
    "    # sort_scores_values = sort_scores.values.cpu().numpy()\n",
    "    # sort_classes = classes[sort_scores_index]\n",
    "\n",
    "    # sorted_masks = masks[:, sort_scores_index]\n",
    "    # sorted_heatmap = heatmap[:, sort_scores_index]\n",
    "\n",
    "    # keep_instances = set()\n",
    "    # pairwise_overlap = sorted_masks.T @ sorted_masks\n",
    "    # normalization = pairwise_overlap.max(axis=0)\n",
    "    # norm_overlaps = pairwise_overlap / normalization\n",
    "\n",
    "    # for instance_id in range(norm_overlaps.shape[0]):\n",
    "    #     # filter out unlikely masks and nearly empty masks\n",
    "    #     # if not(sort_scores_values[instance_id] < 0.3 or sorted_masks[:, instance_id].sum() < 500):\n",
    "    #     if not (\n",
    "    #         sort_scores_values[instance_id]\n",
    "    #         < self.config.general.scores_threshold\n",
    "    #     ):\n",
    "    #         # check if mask != empty\n",
    "    #         if not sorted_masks[:, instance_id].sum() == 0.0:\n",
    "    #             overlap_ids = set(\n",
    "    #                 np.nonzero(\n",
    "    #                     norm_overlaps[instance_id, :]\n",
    "    #                     > self.config.general.iou_threshold\n",
    "    #                 )[0]\n",
    "    #             )\n",
    "\n",
    "    #             if len(overlap_ids) == 0:\n",
    "    #                 keep_instances.add(instance_id)\n",
    "    #             else:\n",
    "    #                 if instance_id == min(overlap_ids):\n",
    "    #                     keep_instances.add(instance_id)\n",
    "\n",
    "    # keep_instances = sorted(list(keep_instances))\n",
    "    # all_pred_classes.append(sort_classes[keep_instances])\n",
    "    # all_pred_masks.append(sorted_masks[:, keep_instances])\n",
    "    # all_pred_scores.append(sort_scores_values[keep_instances])\n",
    "    # all_heatmaps.append(sorted_heatmap[:, keep_instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([71, 51, 71, 71, 51, 51, 71, 71, 71, 71, 71, 71, 71, 71, 51, 71, 71, 71,\n",
       "         71, 71, 71, 71, 51, 51, 71, 71, 51, 71, 71, 51, 51, 51, 71, 71, 71, 71,\n",
       "         51, 71, 51, 71, 51, 71, 51, 51, 51, 71, 71, 71, 71, 71, 71, 51, 51, 71,\n",
       "         71, 71, 71, 51, 51, 71, 71, 71, 71, 71, 71, 71, 71, 71, 51, 51, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 51, 51, 71, 51, 51, 51, 51, 71, 71, 71,\n",
       "         51, 51, 51, 71, 71, 51, 71, 51, 51, 51]),\n",
       " tensor([71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "         71, 71, 71, 71, 71, 71, 71, 71, 71, 71])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
