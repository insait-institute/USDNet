{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mask3d_cuda113/lib/python3.10/site-packages/MinkowskiEngine-0.5.4-py3.10-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# set current dir to Mask3D dir\n",
    "mask3d_dir = \"/workspace/Mask3D_adapted\"\n",
    "os.chdir(mask3d_dir)\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from hashlib import md5\n",
    "from uuid import uuid4\n",
    "import hydra\n",
    "from dotenv import load_dotenv\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from trainer.trainer import InstanceSegmentation, RegularCheckpointing\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from utils.utils import (\n",
    "    flatten_dict,\n",
    "    load_baseline_model,\n",
    "    load_checkpoint_with_missing_or_exsessive_keys,\n",
    "    load_backbone_checkpoint_with_missing_or_exsessive_keys,\n",
    ")\n",
    "from datasets.utils import *\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from random import random, sample, uniform\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "from datasets.random_cuboid import RandomCuboid\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import scipy\n",
    "import volumentations as V\n",
    "import yaml\n",
    "\n",
    "# from yaml import CLoader as Loader\n",
    "from torch.utils.data import Dataset\n",
    "from datasets.scannet200.scannet200_constants import (\n",
    "    SCANNET_COLOR_MAP_200,\n",
    "    SCANNET_COLOR_MAP_20,\n",
    ")\n",
    "MULTISCAN_COLOR_MAP = {0: (0.0, 0.0, 0.0),\n",
    " 1: (191, 246, 112),\n",
    " 2: (110, 239, 148),\n",
    " 255: (0.0, 0.0, 0.0),}\n",
    "from datasets.scannetpp.scannetpp_constants import (SCANNETPP_COLOR_MAP)\n",
    "\n",
    "# models \n",
    "from models.mask3d import *\n",
    "\n",
    "def elastic_distortion(pointcloud, granularity, magnitude):\n",
    "    \"\"\"Apply elastic distortion on sparse coordinate space.\n",
    "\n",
    "    pointcloud: numpy array of (number of points, at least 3 spatial dims)\n",
    "    granularity: size of the noise grid (in same scale[m/cm] as the voxel grid)\n",
    "    magnitude: noise multiplier\n",
    "    \"\"\"\n",
    "    blurx = np.ones((3, 1, 1, 1)).astype(\"float32\") / 3\n",
    "    blury = np.ones((1, 3, 1, 1)).astype(\"float32\") / 3\n",
    "    blurz = np.ones((1, 1, 3, 1)).astype(\"float32\") / 3\n",
    "    coords = pointcloud[:, :3]\n",
    "    coords_min = coords.min(0)\n",
    "\n",
    "    # Create Gaussian noise tensor of the size given by granularity.\n",
    "    noise_dim = ((coords - coords_min).max(0) // granularity).astype(int) + 3\n",
    "    noise = np.random.randn(*noise_dim, 3).astype(np.float32)\n",
    "\n",
    "    # Smoothing.\n",
    "    for _ in range(2):\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurx, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blury, mode=\"constant\", cval=0\n",
    "        )\n",
    "        noise = scipy.ndimage.filters.convolve(\n",
    "            noise, blurz, mode=\"constant\", cval=0\n",
    "        )\n",
    "\n",
    "    # Trilinear interpolate noise filters for each spatial dimensions.\n",
    "    ax = [\n",
    "        np.linspace(d_min, d_max, d)\n",
    "        for d_min, d_max, d in zip(\n",
    "            coords_min - granularity,\n",
    "            coords_min + granularity * (noise_dim - 2),\n",
    "            noise_dim,\n",
    "        )\n",
    "    ]\n",
    "    interp = scipy.interpolate.RegularGridInterpolator(\n",
    "        ax, noise, bounds_error=0, fill_value=0\n",
    "    )\n",
    "    pointcloud[:, :3] = coords + interp(coords) * magnitude\n",
    "    return pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import random\n",
    "from datasets.semseg import SemanticSegmentationArticulationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Mask3D_adapted/datasets/semseg.py:745: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  file = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "dataaset = SemanticSegmentationArticulationDataset(\n",
    "        dataset_name=\"multiscan\",\n",
    "        data_dir = \"data/processed/multiscan\",\n",
    "        label_db_filepath = \"data/processed/multiscan/label_database.yaml\",\n",
    "        color_mean_std = \"data/processed/multiscan/color_mean_std.yaml\",\n",
    "        mode = \"validation\",\n",
    "        add_colors = True,\n",
    "        add_normals = False,\n",
    "        add_raw_coordinates = True,\n",
    "        add_instance = True,\n",
    "        num_labels = 3,\n",
    "        data_percent = 1.0,\n",
    "        ignore_label = 255,\n",
    "        volume_augmentations_path = None,\n",
    "        image_augmentations_path = None,\n",
    "        instance_oversampling=0,\n",
    "        place_around_existing=False,\n",
    "        max_cut_region=0,\n",
    "        point_per_cut=0,\n",
    "        flip_in_center=False,\n",
    "        noise_rate=0.0,\n",
    "        resample_points=0.0,\n",
    "        cache_data=False,\n",
    "        add_unlabeled_pc=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        cropping=False,\n",
    "        cropping_args=None,\n",
    "        is_tta=False,\n",
    "        crop_min_size=20000,\n",
    "        crop_length=6.0,\n",
    "        cropping_v1=True,\n",
    "        reps_per_epoch=1,\n",
    "        area=-1,\n",
    "        on_crops=False,\n",
    "        eval_inner_core=-1,\n",
    "        filter_out_classes=[0, 255],\n",
    "        label_offset=0,\n",
    "        add_clip=False,\n",
    "        is_elastic_distortion=True,\n",
    "        color_drop=0.0,\n",
    "        load_articulation = True\n",
    ")\n",
    "collater = VoxelizeCollate(\n",
    "        ignore_label=255,\n",
    "        voxel_size=0.02,\n",
    "        mode=\"train_mode\",\n",
    "        small_crops=False,\n",
    "        very_small_crops=False,\n",
    "        batch_instance=False,\n",
    "        probing=False,\n",
    "        task=\"instance_segmentation\",\n",
    "        ignore_class_threshold=100,\n",
    "        filter_out_classes=[0, 255],\n",
    "        label_offset=0,\n",
    "        num_queries=150,\n",
    "        load_articulation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataaset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx with empty targets:  16\n",
      "idx with empty targets:  17\n"
     ]
    }
   ],
   "source": [
    "len_dataset = len(dataaset)\n",
    "\n",
    "for i in range(len_dataset):\n",
    "    data_batch = collater([dataaset[i]])\n",
    "    data, target, file_names = data_batch\n",
    "    if len(target) == 0:\n",
    "        print(\"idx with empty targets: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<datasets.utils.NoGpu at 0x7f52944f0df0>,\n",
       " [{'labels': tensor([1, 1, 1, 1, 1]),\n",
       "   'masks': tensor([[False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False]]),\n",
       "   'segment_mask': tensor([[True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True]]),\n",
       "   'articulations': {'origin': tensor([[-1.0510, -1.2066, -0.1470],\n",
       "            [-0.4247, -1.2085, -0.1877],\n",
       "            [ 0.0090,  0.0979, -0.7312],\n",
       "            [-0.1396, -0.4228, -0.8468],\n",
       "            [-0.1389, -0.9218, -0.8342]]),\n",
       "    'axis': tensor([[-9.5923e-03,  0.0000e+00,  9.9995e-01],\n",
       "            [ 3.1177e-02,  9.9951e-01,  2.2194e-16],\n",
       "            [ 0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [ 2.2617e-02, -0.0000e+00,  9.9974e-01]])},\n",
       "   'articulations_dict': {tensor(1004): {'origin': tensor([-1.0510, -1.2066, -0.1470]),\n",
       "     'axis': tensor([-0.0096,  0.0000,  1.0000])},\n",
       "    tensor(1006): {'origin': tensor([-0.4247, -1.2085, -0.1877]),\n",
       "     'axis': tensor([3.1177e-02, 9.9951e-01, 2.2194e-16])},\n",
       "    tensor(1026): {'origin': tensor([ 0.0090,  0.0979, -0.7312]),\n",
       "     'axis': tensor([0., 1., 0.])},\n",
       "    tensor(1029): {'origin': tensor([-0.1396, -0.4228, -0.8468]),\n",
       "     'axis': tensor([ 0.0000e+00,  2.2204e-16, -1.0000e+00])},\n",
       "    tensor(1030): {'origin': tensor([-0.1389, -0.9218, -0.8342]),\n",
       "     'axis': tensor([0.0226, -0.0000, 0.9997])}},\n",
       "   'point2segment': tensor([0, 0, 0,  ..., 0, 0, 0])}],\n",
       " ['scene_00002_01'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = collater([dataaset[1]])\n",
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1005, 1007, 1027, 1030, 1031], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"/workspace/Mask3D_adapted/data/processed/multiscan/instance_gt/validation/scene_00002_01.txt\"\n",
    "test = np.loadtxt(test_file).astype(np.int32)\n",
    "np.unique(test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, 26, 29, 30], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_batch[0].original_labels[0][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, 26, 29, 30], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataaset[1][2][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = data_batch[1][0]['masks']\n",
    "\n",
    "inst_gt = np.zeros(masks.shape[1])\n",
    "for i in range(masks.shape[0]):\n",
    "    inst_mask = masks[i].numpy()\n",
    "    inst_gt[inst_mask] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_batch[0].coordinates[:, 1:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185682, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185682,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test2.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"inst.npy\", inst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<datasets.utils.NoGpu at 0x7fc5f0b37d00>,\n",
       " [{'labels': tensor([1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'masks': tensor([[False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           ...,\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False],\n",
       "           [False, False, False,  ..., False, False, False]]),\n",
       "   'segment_mask': tensor([[True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True],\n",
       "           [True]]),\n",
       "   'articulations': {'origin': tensor([[ 6.3476,  3.2623, -0.4918],\n",
       "            [ 5.6624,  3.5681, -0.3817],\n",
       "            [ 4.0854,  0.6979,  0.6094],\n",
       "            [ 3.3646,  0.6908,  0.6051],\n",
       "            [ 5.8573,  0.9283,  0.8430],\n",
       "            [ 5.8834,  0.9341,  0.8518],\n",
       "            [ 5.8672,  0.0332,  0.8492],\n",
       "            [ 2.8948,  2.8889, -0.3025],\n",
       "            [ 2.9814,  2.2026, -0.2670],\n",
       "            [ 4.0934,  0.6959, -0.0809],\n",
       "            [ 3.3590,  0.6930, -0.0733],\n",
       "            [ 4.0982,  0.7031, -0.7687],\n",
       "            [ 3.3632,  0.6784, -0.9456],\n",
       "            [ 3.3062,  0.6783,  0.4921],\n",
       "            [ 2.3817,  0.6727,  0.5614],\n",
       "            [ 3.2574,  0.6872, -0.5219],\n",
       "            [ 2.3891,  0.7002, -0.5300],\n",
       "            [ 2.3086,  0.6702,  0.5959],\n",
       "            [ 1.4692,  0.6722,  0.8084],\n",
       "            [ 2.2944,  0.6722, -0.0885],\n",
       "            [ 1.4673,  0.6637, -0.0871],\n",
       "            [ 2.3258,  0.6691, -0.9802],\n",
       "            [ 1.4788,  0.6607, -0.9804],\n",
       "            [ 5.8502,  1.8184,  0.8268]]),\n",
       "    'axis': tensor([[-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 4.8266e-03,  0.0000e+00,  9.9999e-01],\n",
       "            [ 2.9345e-02,  0.0000e+00,  9.9957e-01],\n",
       "            [-3.3512e-02,  0.0000e+00, -9.9944e-01],\n",
       "            [ 2.9345e-02,  0.0000e+00,  9.9957e-01],\n",
       "            [-1.4919e-02,  9.9989e-01, -1.7473e-04],\n",
       "            [ 5.0083e-02, -9.9875e-01, -2.2177e-16],\n",
       "            [ 9.0612e-04,  0.0000e+00, -1.0000e+00],\n",
       "            [ 1.0228e-02, -5.8350e-03,  9.9993e-01],\n",
       "            [-1.6870e-02,  0.0000e+00, -9.9986e-01],\n",
       "            [-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [ 0.0000e+00,  2.2204e-16, -1.0000e+00],\n",
       "            [-0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [ 1.3275e-02,  2.5916e-03, -9.9991e-01],\n",
       "            [ 4.8266e-03,  0.0000e+00,  9.9999e-01],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01],\n",
       "            [ 0.0000e+00, -2.2204e-16,  1.0000e+00],\n",
       "            [-4.8266e-03, -0.0000e+00, -9.9999e-01]])},\n",
       "   'point2segment': tensor([0, 0, 0,  ..., 0, 0, 0])}],\n",
       " ['scene_00004_00'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
