<!-- # USDNet -->
<div align='center'>
<h2 align="center"> USDNet </h2>
USDNet is the benchmark method of <a href="https://insait-institute.github.io/articulate3d.github.io/">Articulate3D</a>.  
Given a 3D indoor scene as input, USDNet identifies all movable parts and predict their interaction specifications.  
These include the part's motion characteristics—such as axis, origin, and motion type (rotation or translation)—as well as the specific graspable region that enables interaction (e.g., a door knob or window handle).  
![teaser](./repo_info/method_usdnet.png)
</div>

## News :newspaper:
* **4. July 2025**: Code was made public.
* **25 June 2025**: Articulate3D accepted to ICCV 2025!